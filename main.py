import threading
import queue
import time
import uuid
import itertools

from audio.perception.pipeline import PerceptionPipeline
from audio.processor import VoiceProcessor
from transcribers.router import AsrRouter
from tts.router import LanguageRouterTTS
from memory.manager import MemoryManager
from agents.manager import AgentManager
from utils.sound_player import SoundPlayer  # ç³»çµ±æç¤ºéŸ³æ’­æ”¾å™¨

wakeword_event = threading.Event()
asr_result_queue = queue.Queue()


def handle_wakeword():
    """å–šé†’è©å›èª¿"""
    if not wakeword_event.is_set():
        wakeword_event.set()


def handle_asr_result(result):
    """ASR å›å‚³çš„çµæœï¼Œä½µå…¥æ™‚é–“æˆ³æ–¹ä¾¿é‡æ¸¬å»¶é²"""
    asr_end_time = time.time()
    asr_result_queue.put((result, asr_end_time))


def _safe_last_activity_ts(perception_pipeline) -> float:
    """å®¹éŒ¯ï¼šè‹¥ pipeline æ²’æœ‰ last_activity_ts()ï¼Œç”¨ç•¶å‰æ™‚é–“æ›¿ä»£"""
    try:
        return float(perception_pipeline.last_activity_ts())
    except Exception:
        return time.time()


def main():
    print("ğŸš€ Initializing AI Assistant (Core Components)...")

    global processor
    asr_router = AsrRouter(enable_openai=True)
    agent_manager = AgentManager()

    processor = VoiceProcessor(on_wakeword=handle_wakeword)
    processor.start()

    try:
        while True:
            # ==================================================================
            # --- IDLE STATE ---
            # ==================================================================
            print("\n--- State: IDLE (Waiting for wake word) ---")
            wakeword_event.clear()
            processor.set_state("IDLE")

            wakeword_event.wait()
            print("ğŸ‘‹ Wake word detected! Starting new dialog session...")

            # ==================================================================
            # --- DIALOG SESSION SETUP ---
            # ==================================================================
            print("[Main] Initializing services for the new dialog session...")

            # æ¯æ¬¡å°è©±å»ºç«‹å…¨æ–° TTSï¼ˆé¿å…èˆŠç‹€æ…‹å½±éŸ¿ï¼‰
            tts_router = LanguageRouterTTS(tts_provider="openai")
            sys_tts_router = LanguageRouterTTS(tts_provider="openai-sys")

            # Perception pipelineï¼ˆå« N/M å¹³æ»‘ + å»¶é² duck + commitï¼‰
            perception_pipeline = PerceptionPipeline(
                asr_router=asr_router,
                on_result_callback=handle_asr_result,
                on_speech_onset=lambda: tts_router.duck(-15),
                on_speech_commit=lambda: tts_router.pause_output(flush=False),
                on_speech_cancel=tts_router.unduck,
                on_stop_current_utterance=tts_router.stop_current_utterance,
                on_resume_continue=lambda: tts_router.resume_output(
                    flush=False),
                on_resume_flush=lambda: tts_router.resume_output(flush=True),
                commit_min_ms=360,        # 300â€“450ms çœ‹é«”æ„Ÿ
                onset_duck_delay_ms=150,  # 120â€“180ms çœ‹é«”æ„Ÿ
                window_frames=12,         # M
                window_min_speech=9,      # N
                vad_frame_ms=10,          # 10ms æ›´éˆæ•
            )
            processor.perception_pipeline = perception_pipeline

            # ç³»çµ±æç¤ºéŸ³ï¼šç­‰ç¬¬ä¸€å€‹ token æ™‚å¾ªç’°æ’­æ”¾
            sys_sound_player = SoundPlayer("utils/sys_sound.wav")

            # å•Ÿå‹•èƒŒæ™¯æœå‹™
            perception_pipeline.start()
            if hasattr(tts_router, 'start_stream'):
                tts_router.start_stream()
            if hasattr(sys_tts_router, 'start_stream'):
                sys_tts_router.start_stream()

            SSID = uuid.uuid4()
            current_memory_session = MemoryManager(session_id=SSID)
            processor.set_state("DIALOG")

            # --- DIALOG FSM ---
            current_dialog_state = "GREETING"
            user_text = None
            response_generator = None
            asr_end_time = None  # è¨˜éŒ„æœ€å¾Œä¸€æ¬¡ ASR å®Œæˆæ™‚é–“

            while current_dialog_state != "EXIT":
                print(
                    f"\n[FSM TRACE] Top of loop. Current state: {current_dialog_state}")

                if current_dialog_state == "GREETING":
                    print("--- Dialog State: GREETING ---")
                    # é–‹å ´ç”¨çŸ­æç¤ºéŸ³ï¼Œé¿å… TTS å†·å•Ÿå»¶é²
                    greet_player = SoundPlayer("utils/sys_sound.wav")
                    greet_player.start()
                    time.sleep(1.0)
                    greet_player.stop()
                    current_dialog_state = "LISTENING"

                elif current_dialog_state == "LISTENING":
                    print("--- Dialog State: LISTENING (Waiting for command) ---")
                    perception_pipeline.resume()

                    LISTEN_TIMEOUT = 30.0  # ç§’
                    deadline = time.time() + LISTEN_TIMEOUT
                    last_seen_activity = _safe_last_activity_ts(
                        perception_pipeline)

                    user_text = ""
                    asr_end_time = None

                    while True:
                        remaining = max(0.0, deadline - time.time())
                        poll = min(0.2, remaining) if remaining > 0 else 0.0
                        try:
                            asr_result, asr_end_time = asr_result_queue.get(
                                timeout=poll)
                            txt = (asr_result or {}).get("text", "").strip()
                            if txt:
                                user_text = txt
                                current_dialog_state = "PROCESSING"
                                break
                            else:
                                continue
                        except queue.Empty:
                            pass

                        cur_activity = _safe_last_activity_ts(
                            perception_pipeline)
                        if cur_activity > last_seen_activity:
                            deadline = time.time() + LISTEN_TIMEOUT
                            last_seen_activity = cur_activity

                        if time.time() >= deadline:
                            print(
                                "â° Dialog timed out. Checking for last-second commands...")
                            perception_pipeline.pause()
                            try:
                                final_asr_result, asr_end_time = asr_result_queue.get(
                                    block=False)
                                print(
                                    "ğŸƒâ€â¡ï¸ Caught a last-second command! Processing it...")
                                user_text = (final_asr_result or {}).get(
                                    "text", "").strip()
                                if user_text:
                                    current_dialog_state = "PROCESSING"
                                else:
                                    sys_tts_router.say("See you next time")
                                    current_dialog_state = "EXIT"
                            except queue.Empty:
                                print("No last-second command. Exiting dialog.")
                                sys_tts_router.say("See you next time")
                                current_dialog_state = "EXIT"
                            break  # è·³å‡º LISTENING while

                elif current_dialog_state == "PROCESSING":
                    print(
                        f"--- Dialog State: PROCESSING (User said: '{user_text}') ---")
                    # ç­‰ LLM æœŸé–“ä¸æ”¶éŸ³
                    perception_pipeline.pause()

                    # æ’­æ”¾ç³»çµ±æç¤ºéŸ³ç›´åˆ°ç¬¬ä¸€å€‹ token
                    sys_sound_player.start()

                    agent_start_time = time.time()
                    current_memory_session.add_message("user", user_text)
                    response_generator = agent_manager.stream_request(
                        user_text=user_text, memory=current_memory_session
                    )

                    try:
                        # é˜»å¡æ‹¿åˆ°ç¬¬ä¸€å€‹ token
                        first_chunk = next(response_generator)
                        # ä¸€æ‹¿åˆ°å°±åœæç¤ºéŸ³
                        sys_sound_player.stop()

                        agent_first_token_time = time.time()
                        cognition_latency = (
                            agent_first_token_time - agent_start_time) * 1000
                        print(
                            f"LATENCY_METRIC: Cognition (Agent start -> First token) = {cognition_latency:.2f} ms")

                        if asr_end_time:
                            e2e_latency = (
                                agent_first_token_time - asr_end_time) * 1000
                            print(
                                f"LATENCY_METRIC: ASR End -> First token = {e2e_latency:.2f} ms")

                        if first_chunk == "[EXIT_DIALOG]":
                            print("[Main] User requested to exit. Ending dialog.")
                            current_dialog_state = "EXIT"
                            continue

                        response_generator = itertools.chain(
                            [first_chunk], response_generator)
                        current_dialog_state = "RESPONDING"

                    except StopIteration:
                        sys_sound_player.stop()
                        print(
                            "[Main] Agent returned an empty response. Returning to listening.")
                        current_dialog_state = "LISTENING"
                    except Exception:
                        sys_sound_player.stop()
                        raise

                elif current_dialog_state == "RESPONDING":
                    print("--- Dialog State: RESPONDING (AI speaking via stream) ---")

                    # ç”¨è·¯ç”±å™¨æä¾›çš„å°è£ APIï¼šé–‹å•Ÿä¸²æµï¼ˆå›å‚³ thread + cancel_eventï¼‰
                    tts_thread, tts_cancel_event = tts_router.begin_stream(
                        response_generator)

                    # æ’­æ”¾åŒæ™‚æ¢å¾©æ”¶éŸ³ï¼Œç­‰å¾…å¯èƒ½çš„ barge-in
                    perception_pipeline.resume()

                    interrupted = False
                    while True:
                        # 1) æœ‰æ²’æœ‰ ASR çµæœï¼ˆæ’è©±ï¼‰
                        try:
                            interruption_result, _ = asr_result_queue.get(
                                block=False)
                            interruption_text = (interruption_result or {}).get(
                                'text', '').strip()
                            if interruption_text:
                                print(
                                    f"âš¡ï¸ Valid Interruption: '{interruption_text}'.")
                                user_text = interruption_text
                                interrupted = True

                                # åŸå­å–æ¶ˆèˆŠæµï¼ˆå°è£äº† cancel -> stop_current -> join -> flushï¼‰
                                tts_router.cancel_stream_and_reset(
                                    tts_thread, tts_cancel_event)
                                break
                        except queue.Empty:
                            pass

                        # 2) è‹¥ TTS å·²æ’­å®Œä¸” pipeline æ²’åœ¨è™•ç†ï¼ˆæ²’æœ‰ barge-inï¼‰ï¼Œå³å¯é€€å‡º
                        if (not tts_thread.is_alive()) and (not perception_pipeline.is_processing):
                            break

                        time.sleep(0.05)

                    if interrupted:
                        current_dialog_state = "PROCESSING"
                    else:
                        perception_pipeline.pause()
                        current_dialog_state = "LISTENING"

            # -- End of Dialog Loop --
            print("...Exiting dialog loop, cleaning up session services.")

            # å¾¹åº•åœæ­¢å’Œæ¸…ç†æœå‹™
            if 'tts_router' in locals() and hasattr(tts_router, 'stop_stream'):
                tts_router.stop_stream()
            if 'sys_tts_router' in locals() and hasattr(sys_tts_router, 'stop_stream'):
                sys_tts_router.stop_stream()
            if 'perception_pipeline' in locals() and perception_pipeline:
                perception_pipeline.stop()

            # ä¿éšªï¼šç¢ºä¿ç³»çµ±éŸ³åœæ­¢
            if 'sys_sound_player' in locals() and sys_sound_player:
                sys_sound_player.stop()

            processor.perception_pipeline = None
            while not asr_result_queue.empty():
                asr_result_queue.get_nowait()
            current_memory_session = None

    except KeyboardInterrupt:
        print("\nğŸ›‘ Shutting down...")
    finally:
        print("Gracefully stopping all services...")
        if 'processor' in locals() and processor:
            processor.stop()
        print("All services stopped. Goodbye.")


if __name__ == '__main__':
    processor = None
    main()
